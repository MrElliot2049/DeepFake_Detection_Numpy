{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c07e300d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using standalone keras\n",
      "✅ Weights loaded from best_model.h5\n",
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\adamy\\AppData\\Local\\Temp\\ipykernel_17372\\908086313.py\", line 75, in classify_video\n",
      "    p = model.predict(img, verbose=0)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 16384, but received input with shape (1, 50176)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 224, 224, 3), dtype=float32)\n",
      "  • training=False\n",
      "  • mask=None\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\adamy\\AppData\\Local\\Temp\\ipykernel_17372\\908086313.py\", line 75, in classify_video\n",
      "    p = model.predict(img, verbose=0)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 16384, but received input with shape (1, 50176)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 224, 224, 3), dtype=float32)\n",
      "  • training=False\n",
      "  • mask=None\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\adamy\\AppData\\Local\\Temp\\ipykernel_17372\\908086313.py\", line 75, in classify_video\n",
      "    p = model.predict(img, verbose=0)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 16384, but received input with shape (1, 50176)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 224, 224, 3), dtype=float32)\n",
      "  • training=False\n",
      "  • mask=None\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\adamy\\AppData\\Local\\Temp\\ipykernel_17372\\908086313.py\", line 75, in classify_video\n",
      "    p = model.predict(img, verbose=0)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 16384, but received input with shape (1, 50176)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 224, 224, 3), dtype=float32)\n",
      "  • training=False\n",
      "  • mask=None\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\adamy\\AppData\\Local\\Temp\\ipykernel_17372\\908086313.py\", line 75, in classify_video\n",
      "    p = model.predict(img, verbose=0)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 16384, but received input with shape (1, 50176)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 224, 224, 3), dtype=float32)\n",
      "  • training=False\n",
      "  • mask=None\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 2146, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\blocks.py\", line 1664, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\adamy\\AppData\\Local\\Temp\\ipykernel_17372\\908086313.py\", line 75, in classify_video\n",
      "    p = model.predict(img, verbose=0)\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\adamy\\OneDrive\\Desktop\\DeepFake_Numpy\\tf-env\\lib\\site-packages\\keras\\src\\layers\\input_spec.py\", line 227, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 16384, but received input with shape (1, 50176)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 224, 224, 3), dtype=float32)\n",
      "  • training=False\n",
      "  • mask=None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "\n",
    "# 1) Import Keras (either from TF or standalone)\n",
    "try:\n",
    "    from tensorflow.keras.applications import VGG19\n",
    "    from tensorflow.keras.layers      import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "    from tensorflow.keras.models      import Model\n",
    "    from tensorflow.keras.optimizers  import Adam\n",
    "    print(\"Using tensorflow.keras\")\n",
    "except ModuleNotFoundError:\n",
    "    from keras.applications import VGG19\n",
    "    from keras.layers      import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "    from keras.models      import Model\n",
    "    from keras.optimizers  import Adam\n",
    "    print(\"Using standalone keras\")\n",
    "\n",
    "# 2) Rebuild your trained model architecture\n",
    "def build_detector(input_shape=(224,224,3),\n",
    "                   freeze_upto=15,\n",
    "                   dense_units=128,\n",
    "                   dropout_rate=0.3,\n",
    "                   lr=1e-4):\n",
    "    base = VGG19(weights=None, include_top=False, input_tensor=Input(shape=input_shape))\n",
    "    for layer in base.layers[:freeze_upto]:\n",
    "        layer.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dense(dense_units, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    outputs = Dense(2, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=base.input, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=lr),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 3) Instantiate & load weights\n",
    "model = build_detector()\n",
    "weights_path = \"best_model.h5\"\n",
    "if not os.path.isfile(weights_path):\n",
    "    raise FileNotFoundError(f\"Cannot find weights file: {weights_path}\")\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "print(\"✅ Weights loaded from\", weights_path)\n",
    "\n",
    "# 4) Video classification function\n",
    "def classify_video(uploaded_file):\n",
    "    \"\"\"\n",
    "    uploaded_file: Path to an uploaded video file.\n",
    "    Returns \"Real\" or \"Fake\".\n",
    "    \"\"\"\n",
    "    video_path = uploaded_file.name if hasattr(uploaded_file, \"name\") else uploaded_file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return \"Error: cannot open video.\"\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 1.0\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = int(total / fps)\n",
    "\n",
    "    fake_probs = []\n",
    "    for sec in range(duration):\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, sec * 1000)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        img = img.astype(\"float32\") / 255.0\n",
    "        img = np.expand_dims(img, 0)\n",
    "\n",
    "        p = model.predict(img, verbose=0)\n",
    "        fake_p = float(p[0][1]) if p.shape[-1] == 2 else float(p[0][0])\n",
    "        fake_probs.append(fake_p)\n",
    "\n",
    "    cap.release()\n",
    "    if not fake_probs:\n",
    "        return \"Error: no frames extracted.\"\n",
    "\n",
    "    count = 0 \n",
    "    for prob in fake_probs:\n",
    "        if prob >= 0.45:\n",
    "            count += 1 \n",
    "        \n",
    "    print(fake_probs)\n",
    "    return \"Fake\" if count > len(fake_probs) // 2 else \"Real\"\n",
    "\n",
    "# 5) Gradio interface with a file uploader\n",
    "iface = gr.Interface(\n",
    "    fn=classify_video,\n",
    "    inputs=gr.File(label=\"Upload Video (any format)\"),\n",
    "    outputs=gr.Textbox(label=\"Final Prediction\"),\n",
    "    title=\"Deepfake Video Detector\",\n",
    "    description=\"Upload a video file; the app samples 1 frame per second and labels it Real or Fake.\"\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80d7f66e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Layer\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# 1) Custom Cast layer for loading tf preprocess ops\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "# 1) Custom Cast layer for loading tf preprocess ops\n",
    "class Cast(Layer):\n",
    "    def __init__(self, dtype='float32', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._dtype = dtype\n",
    "    def call(self, inputs):\n",
    "        return tf.cast(inputs, self._dtype)\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({'dtype': self._dtype})\n",
    "        return cfg\n",
    "\n",
    "custom_objects = {'Cast': Cast}\n",
    "\n",
    "# 2) Load your model\n",
    "model_path = \"best_model.h5\"\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "\n",
    "model = load_model(model_path, custom_objects=custom_objects, compile=False)\n",
    "print(\"✅ Loaded model from\", model_path)\n",
    "\n",
    "# 3) Determine the expected input size (height, width)\n",
    "# model.input_shape is typically (None, H, W, 3)\n",
    "_, H, W, _ = model.input_shape\n",
    "IMG_SIZE = (H, W)\n",
    "print(f\"ℹ️ Resizing inputs to {IMG_SIZE}\")\n",
    "\n",
    "# 4) Prediction function\n",
    "def classify_image(img_pil):\n",
    "    try:\n",
    "        # Convert PIL → BGR numpy array\n",
    "        img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)\n",
    "        # Resize to model’s expected dimensions\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "\n",
    "        # Normalize exactly as in training\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = np.expand_dims(img, 0)  # shape (1, H, W, 3)\n",
    "\n",
    "        preds = model.predict(img, verbose=0)\n",
    "        preds = np.squeeze(preds)\n",
    "\n",
    "        # If you have a single sigmoid output\n",
    "        if preds.ndim == 0:\n",
    "            score = float(preds)\n",
    "            label = \"Fake\" if score >= 0.5 else \"Real\"\n",
    "            conf = score\n",
    "        else:\n",
    "            # softmax over 2 classes\n",
    "            idx = int(np.argmax(preds))\n",
    "            label = \"Real\" if idx == 1 else \"Fake\"\n",
    "            conf = float(preds[idx])\n",
    "\n",
    "        return f\"{label} (confidence: {conf:.2f})\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error during prediction:\\n{type(e).__name__}: {e}\"\n",
    "\n",
    "# 5) Gradio app\n",
    "iface = gr.Interface(\n",
    "    fn=classify_image,\n",
    "    inputs=gr.Image(label=\"Upload Image\", type=\"pil\"),\n",
    "    outputs=gr.Textbox(label=\"Prediction\"),\n",
    "    title=\"Deepfake Image Detector\",\n",
    "    description=(\n",
    "        \"Resizes your upload to the model’s required input size, \"\n",
    "        \"then classifies as Real or Fake.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6e771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
